MODEL:

NETWORK:
  type: HAT
  upscale: 2
  in_chans: 4
  img_size: [16, 64]
  window_size: 16
  compress_ratio: 3
  squeeze_factor: 30
  conv_scale: 0.01
  overlap_ratio: 0.5
  img_range: 1.
  depths: [6, 6, 6, 6]
  embed_dim: 96
  num_heads: [6, 6, 6, 6]
  mlp_ratio: 2
  upsampler: 'pixelshuffle'
  resi_connection: '1conv'

TRAIN:
  logger_dir: './logger/'
  train_data_dir: [
    'dataset/TextZoom/train1',
    'dataset/TextZoom/train2',
  ]
  batch_size: 28
  width: 128
  height: 32
  epochs: 500
  cuda: True
  ngpu: 2
  workers: 2
  # resume: './ckpt/vis/model_best.pth'
  resume: ''
  ckpt_dir: './ckpt/'
  voc_type: 'all' #'digits lower upper all'
  saveInterval: 200
  displayInterval: 100 #display loss
  adadelta: False
  lr: 0.001
  adam: True
  beta1: 0.5
  manualSeed: 1234
  max_len: 100
  keep_ratio: False
  down_sample_scale: 2
  loss_type: ContentPercptualLoss # type:[ImageLoss, L1Loss, MSELoss, CRNNImagePercptualLoss, ContentPercptualLoss]

  VAL:
    val_data_dir: [
      'dataset/TextZoom/test/hard',
      'dataset/TextZoom/test/easy',
      'dataset/TextZoom/test/medium',
    ]
    n_vis: 10
    vis_dir: 'demo'
    valInterval: 1000 #-1, val at the end of epoch
    rec_pretrained: 'demo.pth.tar'
    # moran_pretrained: 'moran.pth'
    crnn_pretrained: 'src/model/crnn/crnn.pth'

TEST:
  checkpoint: ''
  test_data_dir: [
  ]

CONVERT:
  image_dir:
  lmdb_dir:
  n_convert: 10
